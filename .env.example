# DeployMind Environment Variables
# Copy to .env and fill in your values: cp .env.example .env

# Groq API (FREE - 1000 requests/day, 6000 tokens/min)
# Get your free API key at: https://console.groq.com/keys
GROQ_API_KEY=gsk_your_key_here

# Alternative: Use Ollama for FREE local inference (no API key needed)
# Install: https://ollama.ai
# GROQ_API_KEY=  # Leave empty to use local Ollama

# AWS Free Tier (12 months free)
AWS_ACCESS_KEY_ID=AKIA_your_key_here
AWS_SECRET_ACCESS_KEY=your_secret_here
AWS_REGION=us-east-1

# GitHub API (free, 5000 req/hr)
GITHUB_TOKEN=ghp_your_token_here

# Database (local Docker)
DATABASE_URL=postgresql://admin:password@localhost:5432/deploymind

# Redis (local Docker)
REDIS_URL=redis://localhost:6379

# Application
ENVIRONMENT=development
LOG_LEVEL=INFO
LOG_FORMAT=json

# Agent Configuration (Groq Models - ALL FREE)
# Primary model for complex reasoning (security, deployments)
DEFAULT_LLM=llama-3.1-70b-versatile
# Fast model for simple tasks (log parsing, health checks)
COST_SAVING_LLM=llama-3.1-8b-instant
# Alternative models: mixtral-8x7b-32768, gemma2-9b-it
# For local Ollama: llama3.1, mistral, qwen2.5
MAX_DEPLOYMENT_TIME_SECONDS=300
HEALTH_CHECK_INTERVAL_SECONDS=10
